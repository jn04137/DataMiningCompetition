{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0        33\n",
      "1        19\n",
      "2        22\n",
      "3        34\n",
      "4        11\n",
      "         ..\n",
      "23472    25\n",
      "23473    23\n",
      "23474    16\n",
      "23475    10\n",
      "23476    19\n",
      "Name: amenities, Length: 23477, dtype: int64]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def set_parser(data):\n",
    "  try:\n",
    "    j1 = len(data.strip('*}*{').split(','))\n",
    "    return j1\n",
    "  except:\n",
    "    return 'problem'\n",
    "\n",
    "df = pd.read_csv('train.csv', converters={'amenities':set_parser}, header=0)\n",
    "\n",
    "y = df[['price']]\n",
    "y.columns\n",
    "\n",
    "amenity_vals = [df['amenities']]\n",
    "print(amenity_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "23477 23477\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from math import isnan\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "\n",
    "def to_float(s):\n",
    "    try:\n",
    "        ret = float(s)\n",
    "    except:\n",
    "        ret = -1\n",
    "    if isnan(ret):\n",
    "        ret = -1\n",
    "    return ret\n",
    "\n",
    "def to_float_avg(s, name_of_col, data_frame):\n",
    "    avg = data_frame[name_of_col].mean()\n",
    "    try:\n",
    "        ret = float(s)\n",
    "    except:\n",
    "        ret = avg\n",
    "    if isnan(ret):\n",
    "        ret = avg\n",
    "    return ret\n",
    "\n",
    "def to_int(s):\n",
    "    try:\n",
    "        ret = int(s)\n",
    "    except:\n",
    "        ret = -1\n",
    "    return ret\n",
    "\n",
    "def to_int_avg(s, name_of_col, data_frame):\n",
    "    avg = data_frame[name_of_col].mean()\n",
    "    try:\n",
    "        ret = int(s)\n",
    "    except:\n",
    "        ret = avg\n",
    "    return ret\n",
    "\n",
    "def json_parser(data):\n",
    "    j1 = json.loads(data)\n",
    "    return j1\n",
    "\n",
    "categories = [x for x in list(set(df['neighbourhood_group_cleansed'])) if type(x) is str]\n",
    "state_categories = [x for x in list(set(df['state'])) if type(x) is str]\n",
    "state_categories = [x for x in list(set(df['state'])) if type(x) is str]\n",
    "room_categories = [x for x in list(set(df['room_type'])) if type(x) is str]\n",
    "super_host_categories = [x for x in list(set(df['host_is_superhost'])) if type(x) is str]\n",
    "bed_type_categories = [x for x in list(set(df['bed_type'])) if type(x) is str]\n",
    "cancellation_policy_categories = [x for x in list(set(df['cancellation_policy'])) if type(x) is str]\n",
    "property_type_categories = [x for x in list(set(df['property_type'])) if type(x) is str]\n",
    "instant_bookable_categories = [x for x in list(set(df['instant_bookable'])) if type(x) is str]\n",
    "instant_bookable_categories = [x for x in list(set(df['instant_bookable'])) if type(x) is str]\n",
    "is_business_travel_categories = [x for x in list(set(df['is_business_travel_ready'])) if type(x) is str]\n",
    "host_verification_categories = [x for x in list(set(df['host_identity_verified'])) if type(x) is str]\n",
    "print(len(categories))\n",
    "\n",
    "def create_feature(row, data_frame):\n",
    "    guest_num = to_int(row.guests_included)\n",
    "    guest_cap = to_int(row.extra_people)\n",
    "    bedrooms = to_int(row.bedrooms)\n",
    "    bathrooms = to_float(row.bathrooms)\n",
    "    beds = to_int(row.beds)\n",
    "    review = to_float(row.review_scores_rating)\n",
    "    review_scores_location = to_float(row.review_scores_location)\n",
    "    cleanliness_review = to_int(row.review_scores_cleanliness)\n",
    "    number_of_reviews = to_int(row.number_of_reviews)\n",
    "    host_listings = to_int(row.calculated_host_listings_count)\n",
    "    accommodates = to_int(row.accommodates)\n",
    "    amenities = to_int(row.amenities)\n",
    "    minimum_nights = to_int(row.minimum_nights)\n",
    "    reviews_per_month = to_float(row.reviews_per_month)\n",
    "    reviews_value = to_float(row.review_scores_value)\n",
    "    review_accuracy = to_float(row.review_scores_accuracy)\n",
    "    review_checkin = to_float(row.review_scores_checkin)\n",
    "    review_communication = to_float(row.review_scores_communication)\n",
    "    one_hot = [int(row.neighbourhood_group_cleansed == category) for category in categories]\n",
    "    two_hot = [int(row.state == state_category) for state_category in state_categories]\n",
    "    three_hot = [int(row.room_type == room_category) for room_category in room_categories]\n",
    "    four_hot = [int(row.host_is_superhost == super_host_category) for super_host_category in super_host_categories]\n",
    "    five_hot = [int(row.bed_type == bed_type_category) for bed_type_category in bed_type_categories]\n",
    "    six_hot = [int(row.cancellation_policy == cancelation_policy_category) for cancelation_policy_category in cancellation_policy_categories]\n",
    "    seven_hot = [int(row.property_type == property_type_category) for property_type_category in property_type_categories]\n",
    "    eight_hot = [int(row.instant_bookable == instant_bookable_category) for instant_bookable_category in instant_bookable_categories]\n",
    "    nine_hot = [int(row.is_business_travel_ready == is_business_travel_category) for is_business_travel_category in is_business_travel_categories]\n",
    "    ten_hot = [int(row.host_identity_verified == host_identity_verified_category) for host_identity_verified_category in host_verification_categories]\n",
    "    \n",
    "    return [\n",
    "        guest_num, \n",
    "        guest_cap, \n",
    "        bathrooms,\n",
    "        accommodates, \n",
    "        beds, \n",
    "        bedrooms,\n",
    "        number_of_reviews, \n",
    "        host_listings,\n",
    "        review_scores_location,\n",
    "        reviews_per_month, \n",
    "        reviews_value, \n",
    "        cleanliness_review,\n",
    "        review_accuracy,\n",
    "        review_checkin,\n",
    "        ] + one_hot + three_hot + four_hot + seven_hot\n",
    "\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "train_X, train_y = [], []\n",
    "\n",
    "for (idx, row) in df.iterrows():\n",
    "    price = to_float(row.price)\n",
    "    feature = create_feature(row, df)\n",
    "    #if row.accommodates == -1:\n",
    "    #    continue\n",
    "    #elif row.room_type == -1:\n",
    "    #    continue\n",
    "\n",
    "    train_X.append(feature)\n",
    "    train_y.append(price)\n",
    "\n",
    "#train_X = scaler.fit_transform(train_X)\n",
    "print(len(train_X), len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "#enc = OneHotEncoder()\n",
    "#print(amenity_vals)\n",
    "#enc.fit(amenity_vals)\n",
    "#amenity_encoded = enc.transfrom(amenity_vals)\n",
    "#print(amenity_encoded.to_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This is for finding best alpha value\n",
    "# 1.5 seems to a be a good value\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=3072)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "''' Creating the neural network '''\n",
    "optimizer = tf.keras.optimizers.Adam(epsilon=1e-3, learning_rate=0.0002)\n",
    "loss = tf.keras.losses.MeanAbsoluteError()\n",
    "def nn():\n",
    "  nn = tf.keras.models.Sequential()\n",
    "  #nn.add(tf.keras.layers.Dense(500, activation='sigmoid'))\n",
    "  #nn.add(tf.keras.layers.Dense(250, activation='relu'))\n",
    "  #nn.add(tf.keras.layers.Dense(180, activation='relu'))\n",
    "  #nn.add(tf.keras.layers.Dense(120, activation='relu'))\n",
    "  #nn.add(tf.keras.layers.Dense(80, activation='relu'))\n",
    "  #nn.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "  #nn.add(tf.keras.layers.Dense(20, activation='relu'))\n",
    "  #nn.add(tf.keras.layers.Dense(1))\n",
    "  nn.add(tf.keras.layers.Dense(500, activation='relu'))\n",
    "  nn.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "  nn.add(tf.keras.layers.Dense(30, activation='relu'))\n",
    "  nn.add(tf.keras.layers.Dense(1))\n",
    "  nn.compile(optimizer=optimizer, loss=loss)\n",
    "  return nn\n",
    "  \n",
    "keras_regr = tf.keras.wrappers.scikit_learn.KerasRegressor(build_fn=nn,epochs=500,batch_size=4096,verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f5854b59f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f5859507550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f5858d9e310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "-46.29840087890625\n"
     ]
    }
   ],
   "source": [
    "\n",
    "''' The lower the score, the better result '''\n",
    "print(np.mean(cross_val_score(keras_regr, train_X, train_y, cv=3, n_jobs=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5856c42be0>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "keras_regr.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[148.98793   79.14942  410.498    ...  57.056202 282.70255   87.09291 ]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_ids, test_X = [], []\n",
    "for (idx, row) in test_df.iterrows():\n",
    "  feature = create_feature(row, test_df)\n",
    "  test_ids.append(row.id)\n",
    "  test_X.append(feature)\n",
    "test_y = keras_regr.predict(test_X)\n",
    "\n",
    "print(test_y)\n",
    "\n",
    "output_df = pd.DataFrame()\n",
    "output_df['Id'] = test_ids\n",
    "output_df['Predicted'] = test_y\n",
    "output_df.to_csv('keras_testing.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "''' Creating the neural network '''\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "def nn():\n",
    "  nn = tf.keras.models.Sequential()\n",
    "  nn.add(tf.keras.layers.Dense(180, activation='relu'))\n",
    "  nn.add(tf.keras.layers.Dense(80, activation='relu'))\n",
    "  nn.add(tf.keras.layers.Dense(1))\n",
    "  nn.compile(optimizer=optimizer, loss=tf.keras.losses.MeanAbsoluteError())\n",
    "  return nn\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8c7240f1d94b58b7ad391c7d1cda0d4e35465f6e237b27e5c4b4739ef98f4ab"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
