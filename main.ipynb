{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 76,
         "metadata": {},
         "outputs": [],
         "source": [
            "import pandas as pd\n",
            "\n",
            "#def set_parser(data):\n",
            "#  try:\n",
            "#    j1 = list(data.strip('*}*{').split(','))\n",
            "#    return j1\n",
            "#  except:\n",
            "#    return 'problem'\n",
            "#\n",
            "#df = pd.read_csv('train.csv', converters={'amenities':set_parser}, header=0)\n",
            "df = pd.read_csv('train.csv')\n",
            "\n",
            "y = df[['price']]\n",
            "\n",
            "\n",
            "# Can make additional columns attributes for amenities\n",
            "#df[['amenities']]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "setA = []\n",
            "count = 0\n",
            "for B in df[['amenities']].values:\n",
            "  setA.append(B)\n",
            "\n",
            "print(np.unique(setA))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 72,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "Index(['id', 'name', 'summary', 'space', 'description', 'experiences_offered',\n",
                     "       'neighborhood_overview', 'notes', 'transit', 'access', 'interaction',\n",
                     "       'house_rules', 'host_id', 'host_name', 'host_since', 'host_location',\n",
                     "       'host_about', 'host_response_time', 'host_response_rate',\n",
                     "       'host_acceptance_rate', 'host_is_superhost', 'host_neighbourhood',\n",
                     "       'host_listings_count', 'host_verifications', 'host_has_profile_pic',\n",
                     "       'host_identity_verified', 'neighbourhood_cleansed',\n",
                     "       'neighbourhood_group_cleansed', 'city', 'state', 'zipcode', 'market',\n",
                     "       'country_code', 'country', 'property_type', 'room_type', 'accommodates',\n",
                     "       'bathrooms', 'bedrooms', 'beds', 'bed_type', 'amenities', 'square_feet',\n",
                     "       'price', 'guests_included', 'extra_people', 'minimum_nights',\n",
                     "       'maximum_nights', 'number_of_reviews', 'first_review', 'last_review',\n",
                     "       'review_scores_rating', 'review_scores_accuracy',\n",
                     "       'review_scores_cleanliness', 'review_scores_checkin',\n",
                     "       'review_scores_communication', 'review_scores_location',\n",
                     "       'review_scores_value', 'instant_bookable', 'is_business_travel_ready',\n",
                     "       'cancellation_policy', 'require_guest_profile_picture',\n",
                     "       'require_guest_phone_verification', 'calculated_host_listings_count',\n",
                     "       'reviews_per_month'],\n",
                     "      dtype='object')"
                  ]
               },
               "execution_count": 72,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "df.columns"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 87,
         "metadata": {},
         "outputs": [],
         "source": [
            "df.to_csv('train_w_amenities.csv')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 77,
         "metadata": {},
         "outputs": [
            {
               "ename": "TypeError",
               "evalue": "'dict' object is not callable",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                  "\u001b[0;32m/tmp/ipykernel_71546/3054585556.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mj1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neighbourhood_group_cleansed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mstate_categories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mstate_categories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;31mTypeError\u001b[0m: 'dict' object is not callable"
               ]
            }
         ],
         "source": [
            "import json\n",
            "from math import isnan\n",
            "\n",
            "def to_float(s):\n",
            "    try:\n",
            "        ret = float(s)\n",
            "    except:\n",
            "        ret = -1\n",
            "    if isnan(ret):\n",
            "        ret = -1\n",
            "    return ret\n",
            "\n",
            "def to_float_avg(s, name_of_col):\n",
            "    avg = df[name_of_col].mean()\n",
            "    try:\n",
            "        ret = float(s)\n",
            "    except:\n",
            "        ret = avg\n",
            "    if isnan(ret):\n",
            "        ret = avg\n",
            "    return ret\n",
            "\n",
            "def to_int(s):\n",
            "    try:\n",
            "        ret = int(s)\n",
            "    except:\n",
            "        ret = -1\n",
            "    return ret\n",
            "\n",
            "def to_int_avg(s, name_of_col):\n",
            "    avg = df[name_of_col].mean()\n",
            "    try:\n",
            "        ret = int(s)\n",
            "    except:\n",
            "        ret = avg\n",
            "    return ret\n",
            "\n",
            "def json_parser(data):\n",
            "    j1 = json.loads(data)\n",
            "    return j1\n",
            "\n",
            "categories = [x for x in list(set(df['neighbourhood_group_cleansed'])) if type(x) is str]\n",
            "state_categories = [x for x in list(set(df['state'])) if type(x) is str]\n",
            "state_categories = [x for x in list(set(df['state'])) if type(x) is str]\n",
            "room_categories = [x for x in list(set(df['room_type'])) if type(x) is str]\n",
            "super_host_categories = [x for x in list(set(df['host_is_superhost'])) if type(x) is str]\n",
            "bed_type_categories = [x for x in list(set(df['bed_type'])) if type(x) is str]\n",
            "cancellation_policy_categories = [x for x in list(set(df['cancellation_policy'])) if type(x) is str]\n",
            "property_type_categories = [x for x in list(set(df['property_type'])) if type(x) is str]\n",
            "print(len(categories))\n",
            "\n",
            "def create_feature(row):\n",
            "    guest_num = to_int(row.guests_included)\n",
            "    guest_cap = to_float(row.extra_people)\n",
            "    bedrooms = to_int_avg(row.bedrooms, 'bedrooms')\n",
            "    bathrooms = to_int_avg(row.bathrooms, 'bathrooms')\n",
            "    beds = to_int_avg(row.beds, 'beds')\n",
            "    review = to_float(row.review_scores_rating)\n",
            "    review_scores_location = to_float(row.review_scores_location)\n",
            "    cleanliness_review = to_int(row.review_scores_cleanliness)\n",
            "    number_of_reviews = to_int_avg(row.number_of_reviews, 'number_of_reviews')\n",
            "    host_listings = to_int(row.calculated_host_listings_count)\n",
            "    accommodates = to_int_avg(row.accommodates, 'accommodates')\n",
            "    amenities = to_int_avg(row.amenities, 'amenities')\n",
            "    reviews_per_month = to_float_avg(row.reviews_per_month, 'reviews_per_month')\n",
            "    one_hot = [int(row.neighbourhood_group_cleansed == category) for category in categories]\n",
            "    two_hot = [int(row.state == state_category) for state_category in state_categories]\n",
            "    three_hot = [int(row.room_type == room_category) for room_category in room_categories]\n",
            "    four_hot = [int(row.host_is_superhost == super_host_category) for super_host_category in super_host_categories]\n",
            "    five_hot = [int(row.bed_type == bed_type_category) for bed_type_category in bed_type_categories]\n",
            "    six_hot = [int(row.cancellation_policy == cancelation_policy_category) for cancelation_policy_category in cancellation_policy_categories]\n",
            "    seven_hot = [int(row.property_type == property_type_category) for property_type_category in property_type_categories]\n",
            "    \n",
            "    return [guest_num, guest_cap, accommodates, amenities, bedrooms, bathrooms, beds, number_of_reviews, reviews_per_month] + one_hot + three_hot + four_hot + five_hot + seven_hot\n",
            "\n",
            "\n",
            "def preprocess(df):\n",
            "\n",
            "    train_X = []\n",
            "    train_y = []\n",
            "\n",
            "    for (idx, row) in df.iterrows():\n",
            "        price = to_float(row.price)\n",
            "        feature = create_feature(row)\n",
            "\n",
            "        train_X.append(feature)\n",
            "        train_y.append(price)\n",
            "    return train_X, train_y\n",
            "\n",
            "\n",
            "train_X, train_y = preprocess(df)\n",
            "print(len(train_X), len(train_y))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 33,
         "metadata": {},
         "outputs": [],
         "source": [
            "from sklearn.neural_network import MLPRegressor\n",
            "from sklearn.preprocessing import StandardScaler\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.model_selection import cross_val_score\n",
            "import numpy as np\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "\n",
            "# This is for finding best alpha value\n",
            "# 1.5 seems to a be a good value\n",
            "import matplotlib.pyplot as plt\n",
            "scaler_X = StandardScaler().fit(train_X)\n",
            "scaler_X.transform(train_X)\n",
            "\n",
            "scores = []\n",
            "alphas = []\n",
            "for i in np.linspace(1.5, 4.0, 20):\n",
            "  print(i)\n",
            "  score = cross_val_score(MLPRegressor(activation='logistic', alpha=i, hidden_layer_sizes=(8,), random_state=1, max_iter=1600), train_X, train_y, cv=3, n_jobs=8)\n",
            "  scores.append(np.mean(score))\n",
            "  alphas.append(i) \n",
            "plt.plot(alphas, scores)\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 35,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "0.4661272318309931\n"
               ]
            }
         ],
         "source": [
            "\n",
            "\n",
            "# This cell is used for cross validation of the model\n",
            "\n",
            "# scaler_X = StandardScaler().fit(train_X)\n",
            "# scaler_X.transform(train_X)\n",
            "\n",
            "# With standardized X\n",
            "# Setting up the neural net classifier\n",
            "regr = MLPRegressor(activation='logistic', alpha=1.4, hidden_layer_sizes=(180,80,30), random_state=1, max_iter=1800)\n",
            "\n",
            "print(np.mean(cross_val_score(regr, train_X, train_y, cv=5, n_jobs=12)))\n",
            "\n",
            "bestSize = 0\n",
            "bestAvg = 0\n",
            "\n",
            "#for i in range(1, 50):\n",
            "#  score = cross_val_score(MLPRegressor(activation='relu', alpha=1e-05, hidden_layer_sizes=(i,), random_state=1, max_iter=300), train_X, train_y, cv=5, n_jobs=4)\n",
            "#  if(np.mean(score) > bestAvg):\n",
            "#    bestAvg = np.mean(score)\n",
            "#    bestSize = i\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 53,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "MLPRegressor(activation='logistic', alpha=1.4, hidden_layer_sizes=(200, 50, 20),\n",
                     "             max_iter=1800, random_state=1)"
                  ]
               },
               "execution_count": 53,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "regr.fit(train_X, train_y)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 44,
         "metadata": {},
         "outputs": [],
         "source": [
            "test_df = pd.read_csv('test.csv')\n",
            "test_ids, test_X = [], []\n",
            "for (idx, row) in test_df.iterrows():\n",
            "  feature = create_feature(row)\n",
            "  test_ids.append(row.id)\n",
            "  test_X.append(feature)\n",
            "test_y = regr.predict(test_X)\n",
            "\n",
            "\n",
            "output_df = pd.DataFrame()\n",
            "output_df['Id'] = test_ids\n",
            "output_df['Predicted'] = test_y\n",
            "output_df.to_csv('mlpregressor_prediction.csv', index=False)\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 57,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "0.5015955766426005\n"
               ]
            }
         ],
         "source": [
            "\n",
            "scaler_X = StandardScaler().fit(train_X)\n",
            "scaler_X.transform(train_X)\n",
            "\n",
            "# With standardized X\n",
            "# Setting up the neural net classifier\n",
            "regr = MLPRegressor(activation='logistic', alpha=1.4, hidden_layer_sizes=(120,100,30), random_state=1, max_iter=1800)\n",
            "\n",
            "print(np.mean(cross_val_score(regr, train_X, train_y, cv=5, n_jobs=12)))\n",
            "\n",
            "bestSize = 0\n",
            "bestAvg = 0\n",
            "\n",
            "#for i in range(1, 50):\n",
            "#  score = cross_val_score(MLPRegressor(activation='relu', alpha=1e-05, hidden_layer_sizes=(i,), random_state=1, max_iter=300), train_X, train_y, cv=5, n_jobs=4)\n",
            "#  if(np.mean(score) > bestAvg):\n",
            "#    bestAvg = np.mean(score)\n",
            "#    bestSize = i\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 20,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "0.5515102997703232\n"
               ]
            }
         ],
         "source": [
            "\n",
            "\n",
            "# This cell is used for cross validation of the model\n",
            "scaler_X = StandardScaler().fit(train_X)\n",
            "scaler_X.transform(train_X)\n",
            "\n",
            "# With standardized X\n",
            "# Setting up the neural net classifier\n",
            "regr = MLPRegressor(activation='logistic', alpha=1.4, hidden_layer_sizes=(180,120,30), random_state=1, max_iter=1800)\n",
            "\n",
            "print(np.mean(cross_val_score(regr, train_X, train_y, cv=5, n_jobs=12)))\n",
            "\n",
            "bestSize = 0\n",
            "bestAvg = 0\n",
            "\n",
            "#for i in range(1, 50):\n",
            "#  score = cross_val_score(MLPRegressor(activation='relu', alpha=1e-05, hidden_layer_sizes=(i,), random_state=1, max_iter=300), train_X, train_y, cv=5, n_jobs=4)\n",
            "#  if(np.mean(score) > bestAvg):\n",
            "#    bestAvg = np.mean(score)\n",
            "#    bestSize = i\n"
         ]
      }
   ],
   "metadata": {
      "interpreter": {
         "hash": "b8c7240f1d94b58b7ad391c7d1cda0d4e35465f6e237b27e5c4b4739ef98f4ab"
      },
      "kernelspec": {
         "display_name": "Python 3.9.7 ('base')",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.9.7"
      },
      "orig_nbformat": 4
   },
   "nbformat": 4,
   "nbformat_minor": 2
}